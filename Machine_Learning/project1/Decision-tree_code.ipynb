{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\nimport numpy as np\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom scipy.stats import randint\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\n\n#CIFAR\nCIFAR_transform_train = transforms.Compose([transforms.ToTensor()])\nCIFAR_transform_test = transforms.Compose([transforms.ToTensor()])\n\ntrainset_CIFAR = datasets.CIFAR10(root='./data', train=True, download=True, transform=CIFAR_transform_train)\ntestset_CIFAR = datasets.CIFAR10(root='./data', train=False, download=True, transform=CIFAR_transform_test)\n\nCIFAR_train = DataLoader(trainset_CIFAR, batch_size=32, shuffle=True, num_workers=2) \nCIFAR_test = DataLoader(testset_CIFAR, batch_size=32, shuffle=False, num_workers=2)\n\nCIFAR_train_images = [] \nCIFAR_train_labels = [] \nfor batch in CIFAR_train:\n    images, labels = batch\n    images_flat = images.view(images.shape[0], -1)\n    CIFAR_train_images.append(images_flat.numpy())\n    CIFAR_train_labels.append(labels.numpy())\n    \nCIFAR_train_images = np.vstack(CIFAR_train_images) \nCIFAR_train_labels = np.concatenate(CIFAR_train_labels)\n    \nCIFAR_test_images = [] \nCIFAR_test_labels = []\nfor batch in CIFAR_test:\n    images, labels = batch \n    images_flat = images.view(images.shape[0], -1) \n    CIFAR_test_images.append(images_flat.numpy()) \n    CIFAR_test_labels.append(labels.numpy())\n\nCIFAR_test_images = np.vstack(CIFAR_test_images) \nCIFAR_test_labels = np.concatenate(CIFAR_test_labels)\n\n# MNIST \nmnist_train_transform = transforms.Compose([transforms.ToTensor()]) \nmnist_test_transform = transforms.Compose([transforms.ToTensor()])\n\ntrainset_mnist = datasets.MNIST(root='./data', train=True, download=True, transform=mnist_train_transform)\ntestset_mnist = datasets.MNIST(root='./data', train=False, download=True, transform=mnist_test_transform)\n\nMNIST_train = DataLoader(trainset_mnist, batch_size=32, shuffle=True, num_workers=2) \nMNIST_test = DataLoader(testset_mnist, batch_size=32, shuffle=False, num_workers=2)\n\nMNIST_train_images = [] \nMNIST_train_labels = [] \nfor batch in MNIST_train:\n    images, labels = batch \n    images_flat = images.view(images.shape[0], -1) \n    MNIST_train_images.append(images_flat.numpy()) \n    MNIST_train_labels.append(labels.numpy())\nMNIST_train_images = np.vstack(MNIST_train_images) \nMNIST_train_labels = np.concatenate(MNIST_train_labels)\n\nMNIST_test_images = [] \nMNIST_test_labels = [] \nfor batch in MNIST_test: \n    images, labels = batch \n    images_flat = images.view(images.shape[0], -1) \n    MNIST_test_images.append(images_flat.numpy()) \n    MNIST_test_labels.append(labels.numpy()) \nMNIST_test_images = np.vstack(MNIST_test_images) \nMNIST_test_labels = np.concatenate(MNIST_test_labels)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-17T02:47:31.052703Z","iopub.execute_input":"2023-04-17T02:47:31.053143Z","iopub.status.idle":"2023-04-17T02:48:02.547865Z","shell.execute_reply.started":"2023-04-17T02:47:31.053104Z","shell.execute_reply":"2023-04-17T02:48:02.546003Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/170498071 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6851caa9ac0f4834b2f6b597f2298781"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9912422 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7e463ce3014e8481fddb26179c1ee5"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28881 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b7dde27eebf44d08efafd66056b8bb8"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1648877 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"370ede753e754679ace135e5d8ddbb8e"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4542 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1efff453a484470792721133a7a41037"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set hyperparameter grid\nparams_grid = {'min_samples_split': [2, 5, 10],\n               'min_samples_leaf': [1, 2, 4],\n               'max_leaf_nodes': [5, 10, None]}\n\n# Train and evaluate decision tree on CIFAR-10\nfor depth in [3, 6, 9, 12]:\n    print(f\"Depth: {depth}\")\n    \n    # Define decision tree with given depth\n    dt = DecisionTreeClassifier(max_depth=depth)\n    \n    # Define grid search with decision tree and hyperparameter grid\n    gs = GridSearchCV(dt, params_grid, cv=5, n_jobs=-1)\n    \n    # Train grid search on CIFAR-10 training set\n    gs.fit(CIFAR_train_images, CIFAR_train_labels)\n    \n    # Retrieve decision tree with best hyperparameters\n    dt = gs.best_estimator_\n    \n    # Predict CIFAR-10 test set labels and compute accuracy\n    CIFAR_pred_labels = dt.predict(CIFAR_test_images)\n    CIFAR_accuracy = accuracy_score(CIFAR_test_labels, CIFAR_pred_labels)\n    \n    # Predict CIFAR-10 training set labels and compute accuracy\n    CIFAR_train_pred_labels = dt.predict(CIFAR_train_images)\n    CIFAR_train_accuracy = accuracy_score(CIFAR_train_labels, CIFAR_train_pred_labels)\n    \n    print(f\"CIFAR-10 Accuracy (test set): {CIFAR_accuracy:.4f}\")\n    print(f\"CIFAR-10 Accuracy (training set): {CIFAR_train_accuracy:.4f}\")\n    \n    # Train and evaluate decision tree on MNIST\n    # Define decision tree with given depth\n    dt = DecisionTreeClassifier(max_depth=depth)\n    \n    # Train decision tree on MNIST training set\n    dt.fit(MNIST_train_images, MNIST_train_labels)\n    \n    # Predict MNIST test set labels and compute accuracy\n    MNIST_pred_labels = dt.predict(MNIST_test_images)\n    MNIST_accuracy = accuracy_score(MNIST_test_labels, MNIST_pred_labels)\n    \n    # Predict MNIST training set labels and compute accuracy\n    MNIST_train_pred_labels = dt.predict(MNIST_train_images)\n    MNIST_train_accuracy = accuracy_score(MNIST_train_labels, MNIST_train_pred_labels)\n    \n    print(f\"MNIST Accuracy (test set): {MNIST_accuracy:.4f}\")\n    print(f\"MNIST Accuracy (training set): {MNIST_train_accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:48:02.551244Z","iopub.execute_input":"2023-04-17T02:48:02.552155Z","iopub.status.idle":"2023-04-17T05:26:17.978758Z","shell.execute_reply.started":"2023-04-17T02:48:02.552106Z","shell.execute_reply":"2023-04-17T05:26:17.976829Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Depth: 3\nCIFAR-10 Accuracy (test set): 0.2394\nCIFAR-10 Accuracy (training set): 0.2376\nMNIST Accuracy (test set): 0.4953\nMNIST Accuracy (training set): 0.4915\nDepth: 6\nCIFAR-10 Accuracy (test set): 0.2812\nCIFAR-10 Accuracy (training set): 0.2959\nMNIST Accuracy (test set): 0.7415\nMNIST Accuracy (training set): 0.7382\nDepth: 9\nCIFAR-10 Accuracy (test set): 0.3043\nCIFAR-10 Accuracy (training set): 0.3821\nMNIST Accuracy (test set): 0.8504\nMNIST Accuracy (training set): 0.8665\nDepth: 12\nCIFAR-10 Accuracy (test set): 0.3038\nCIFAR-10 Accuracy (training set): 0.5188\nMNIST Accuracy (test set): 0.8798\nMNIST Accuracy (training set): 0.9492\n","output_type":"stream"}]}]}